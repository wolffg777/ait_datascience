{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolffg777/ait_datascience/blob/main/MusicRec01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZxf-Kh9WfmB"
      },
      "source": [
        "TODO:\n",
        "WORD2VEC KERAS CLASSIFICATION PROBLEM\n",
        "- first clean up\n",
        "- testing it to see improvement\n",
        "- implementing primary_genres and secondary_genres as inputs\n",
        "- implement output as album-artist name pair\n",
        "- implementing dates (as continuous)\n",
        "- easier things first\n",
        "- spotify data integration\n",
        "\n",
        "\n",
        "-brainstorm an idea for the name of the independent study on askbanner (limited to 30 characters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4x6IYS2o--9"
      },
      "source": [
        "\n",
        "check - train on domain text\n",
        "notcheck - pretrained w2v\n",
        "notcheck - use pretrained with domain adaptation  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "lYKfT639cxos",
        "outputId": "cac7a1e6-432a-4711-a539-29525e808192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-154e92f1-4776-49ff-b632-4efb344f3eef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-154e92f1-4776-49ff-b632-4efb344f3eef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading rym-top-5000.zip to /content\n",
            "100% 863k/863k [00:00<00:00, 925kB/s]\n",
            "100% 863k/863k [00:00<00:00, 925kB/s]\n",
            "Archive:  rym-top-5000.zip\n",
            "  inflating: rym_clean1.csv          \n",
            "  inflating: rym_raw1.csv            \n",
            "Collecting spotipy\n",
            "  Downloading spotipy-2.23.0-py3-none-any.whl (29 kB)\n",
            "Collecting redis>=3.5.3 (from spotipy)\n",
            "  Downloading redis-5.0.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.31.0)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.0.7)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from redis>=3.5.3->spotipy) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (2023.7.22)\n",
            "Installing collected packages: redis, spotipy\n",
            "Successfully installed redis-5.0.1 spotipy-2.23.0\n"
          ]
        }
      ],
      "source": [
        "#Downloading Google's Word2Vec model\n",
        "# import gensim.downloader as api\n",
        "# path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
        "# print(path)\n",
        "\n",
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Downloading Google's Word2Vec model to Google Drive\n",
        "# datafiles_folder_path = \"/content/drive/MyDrive/DataFiles/word2vec-google-news-300\"\n",
        "# !cp $path $datafiles_folder_path\n",
        "\n",
        "#installs\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!pip install kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d tobennao/rym-top-5000\n",
        "!unzip rym-top-5000.zip\n",
        "!pip install spotipy\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "# #Decompress w2v model\n",
        "# import gzip\n",
        "# with gzip.open('/content/drive/MyDrive/DataFiles/word2vec-google-news-300', 'rb') as f_in:\n",
        "#     with open('/content/drive/MyDrive/DataFiles/word2vec-google-news-300.bin', 'wb') as f_out:\n",
        "#         f_out.write(f_in.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DvZgb6D6hVUo"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6qKZMPKbqyuJ"
      },
      "outputs": [],
      "source": [
        "# Load w2v model\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/DataFiles/word2vec-google-news-300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1WScY1v6BmPE"
      },
      "outputs": [],
      "source": [
        "def loadData():\n",
        "  #Load data\n",
        "  df = pd.read_csv('rym_clean1.csv')\n",
        "\n",
        "  # Remove unnecessary columns\n",
        "  df = df.drop(columns=['avg_rating'])\n",
        "  df = df.drop(columns=['rating_count'])\n",
        "  df = df.drop(columns=['review_count'])\n",
        "  df = df.drop(columns=['Unnamed: 0'])\n",
        "  df = df.drop(columns=['position'])\n",
        "  df = df.drop(columns=['release_type'])\n",
        "  df = df.drop(columns=['artist_name'])\n",
        "  df = df.drop(columns=['release_date'])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xTO2ICpzY6eG"
      },
      "outputs": [],
      "source": [
        "def filter(df):\n",
        "  #Reformat descriptors properly\n",
        "  df['descriptors'] = df['descriptors'].str.split(', ')\n",
        "\n",
        "  # Removing rare descriptors\n",
        "  MIN_OCCURRENCE_OF_DESCRIPTORS = 5\n",
        "\n",
        "  # Flatten the list of all descriptors and count their occurrences\n",
        "  all_descriptors = [descriptor for descriptors in df['descriptors'] for descriptor in descriptors]\n",
        "  descriptor_frequency = pd.Series(all_descriptors).value_counts()\n",
        "\n",
        "  # Filter out rare descriptors\n",
        "  rare_descriptors = descriptor_frequency[descriptor_frequency < MIN_OCCURRENCE_OF_DESCRIPTORS].index\n",
        "  df['descriptors'] = df['descriptors'].apply(lambda descriptors: [descriptor for descriptor in descriptors if descriptor not in rare_descriptors])\n",
        "\n",
        "  # Removing albums below a minimum number of descriptors\n",
        "  MIN_DESCRIPTORS_PER_ALBUM = 5  # Minimum number of descriptors per album\n",
        "  df = df[df['descriptors'].map(len) >= MIN_DESCRIPTORS_PER_ALBUM]\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I_8PRvkUJGo5"
      },
      "outputs": [],
      "source": [
        "def tokenize(df):\n",
        "  #Tokenize descriptors\n",
        "  texts = df['descriptors'].tolist()\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "  return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "83LZfuuQJIJ8"
      },
      "outputs": [],
      "source": [
        "def vectorize(df):\n",
        "  def descriptors_to_vector(descriptors):\n",
        "      #Vectorize descriptors\n",
        "\n",
        "      vectors = [model[word] for word in descriptors if word in model]\n",
        "      if vectors:\n",
        "          return np.mean(vectors, axis=0)\n",
        "      else:\n",
        "          return np.zeros(model.vector_size)\n",
        "\n",
        "  # Apply the function to the dataframe\n",
        "  df['vector'] = df['descriptors'].apply(descriptors_to_vector)\n",
        "\n",
        "  # Convert df to nparray\n",
        "  df_nparray = np.array(df['vector'].tolist())\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B0__DaMdNl2H"
      },
      "outputs": [],
      "source": [
        "def makeTokenizer(df):\n",
        "  texts = df['descriptors'].tolist()\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K6DJK0-_JKZv"
      },
      "outputs": [],
      "source": [
        "def embed(df):\n",
        "  tokenizer = makeTokenizer(df)\n",
        "  embedding_dim = 300  # As the Word2Vec model you downloaded has 300 dimensions\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  # Create an embedding matrix\n",
        "  embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "  for word, i in tokenizer.word_index.items():  # tokenizer should be the tokenizer you used to process your text\n",
        "      if word in model:\n",
        "          embedding_vector = model[word]\n",
        "          if embedding_vector is not None:\n",
        "              embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DMTiXYQNJX6h"
      },
      "outputs": [],
      "source": [
        "def encode(df):\n",
        "  encoder = LabelEncoder()\n",
        "  df['release_name_label'] = encoder.fit_transform(df['release_name'])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tg-pJ342Igm"
      },
      "outputs": [],
      "source": [
        "# Model 1\n",
        "\n",
        "def model1(X_train, X_val, y_train, y_val, df, df_nparray, embedding_matrix) :\n",
        "\n",
        "  modelSeq = Sequential([\n",
        "      Embedding(input_dim=len(makeTokenizer(df).word_index) + 1, output_dim=300, input_length=df_nparray.shape[1],\n",
        "               weights=[embedding_matrix], trainable=False),  # Using pre-trained embeddings and setting them non-trainable\n",
        "\n",
        "     #change lstm to deep feedforward nn\n",
        "      LSTM(128, return_sequences=True),  # Return sequences if you want to stack LSTMs\n",
        "     Dropout(0.2),  # Add dropout for regularization\n",
        "      LSTM(64),  # Another LSTM layer\n",
        "      Dropout(0.2),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(len(df['release_name'].unique()), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  modelSeq.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Callbacks\n",
        "  early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
        "  model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "  # Assuming you've created a validation set called X_val and y_val\n",
        "  history = modelSeq.fit(X, y, epochs=25, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stop, model_checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rSnb8tRa2U9t"
      },
      "outputs": [],
      "source": [
        "# Model 2\n",
        "# does not use embedding, simpler design, sequential not an lstm\n",
        "\n",
        "def model2(X_train, X_val, y_train, y_val, df, df_nparray):\n",
        "  modelSeq = Sequential([\n",
        "     Dense(128, activation='relu', input_shape=(df_nparray.shape[1],)),\n",
        "      Dropout(0.2),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.2),\n",
        "      Dense(len(df['release_name'].unique()), activation='softmax')\n",
        "    ])\n",
        "\n",
        "  modelSeq.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Callbacks remain the same\n",
        "  early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
        "  model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "  # Train the model\n",
        "  history = modelSeq.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stop, model_checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t82Iqq23YUpU"
      },
      "outputs": [],
      "source": [
        "# Method1: Baseline Data (descriptors --> album titles, really bad)\n",
        "df = loadData()\n",
        "df = filter(df)\n",
        "sequences = tokenize(df)\n",
        "df = vectorize(df)\n",
        "df = encode(df)\n",
        "\n",
        "df_nparray = np.array(df['vector'].tolist())\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array(df_nparray, dtype='float32')\n",
        "y = df['release_name_label'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1z98tnaLRkhN"
      },
      "outputs": [],
      "source": [
        "# Method2: Clustering Albums\n",
        "df = loadData()\n",
        "df = filter(df)\n",
        "sequences = tokenize(df)\n",
        "df = vectorize(df)\n",
        "df = encode(df)\n",
        "\n",
        "df_nparray = np.array(df['vector'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv2ffBLTpI-o"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# inertia = []\n",
        "# for k in range(1, 1000, 50):  # Adjust the range of k as needed\n",
        "#     kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "#     kmeans.fit_predict(df_nparray)  # Assuming df_nparray is your feature array\n",
        "#     inertia.append(kmeans.inertia_)\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(range(1, 1000, 50), inertia, marker='o')\n",
        "# plt.title('Elbow Method')\n",
        "# plt.xlabel('Number of clusters')\n",
        "# plt.ylabel('Inertia')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4HtpPxdQo5pG"
      },
      "outputs": [],
      "source": [
        "k = 100\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "df['cluster_label'] = kmeans.fit_predict(df_nparray)\n",
        "\n",
        "X = np.array(df_nparray, dtype='float32')\n",
        "y = df['cluster_label'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR7WIgVakrs9"
      },
      "source": [
        "k = 50 --> ~70% accuracy,\n",
        "k = 100 --> 55% accuracy,\n",
        "k = 250 --> 35% accuracy,\n",
        "k = 500 --> ~30% accuracy,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ZBOyHOCQz3",
        "outputId": "89dec0d4-fa97-4b59-d265-30f4c86abf4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                       release_name  \\\n",
            "66                                     Led Zeppelin   \n",
            "84                                  Led Zeppelin II   \n",
            "141   Whatever People Say I Am, That's What I'm Not   \n",
            "216                                    Aladdin Sane   \n",
            "254                                  Sticky Fingers   \n",
            "...                                             ...   \n",
            "4893                                          Loose   \n",
            "4924                                  A Bigger Bang   \n",
            "4945                                Scissor Sisters   \n",
            "4952                               Feed the Animals   \n",
            "4972                                       Elephunk   \n",
            "\n",
            "                                            descriptors  \n",
            "66    [energetic, heavy, malevocals, raw, sexual, pa...  \n",
            "84    [energetic, sexual, heavy, malevocals, raw, he...  \n",
            "141   [urban, energetic, sarcastic, malevocals, raw,...  \n",
            "216   [malevocals, melodic, playful, energetic, pass...  \n",
            "254   [drugs, sexual, malevocals, energetic, hedonis...  \n",
            "...                                                 ...  \n",
            "4893  [sexual, party, rhythmic, energetic, femalevoc...  \n",
            "4924    [sexual, malevocals, energetic, playful, urban]  \n",
            "4945  [sexual, quirky, playful, LGBT, rhythmic, andr...  \n",
            "4952  [party, sampling, energetic, rhythmic, hedonis...  \n",
            "4972  [malevocals, hedonistic, femalevocals, party, ...  \n",
            "\n",
            "[76 rows x 2 columns]\n",
            "76\n"
          ]
        }
      ],
      "source": [
        "cluster_number = 0  # Replace with the cluster number you are interested in\n",
        "\n",
        "# Filter the DataFrame to only include rows belonging to the specified cluster\n",
        "cluster_members = df[df['cluster_label'] == cluster_number]\n",
        "\n",
        "# Print the information of interest from these rows\n",
        "# For example, printing album names and descriptors\n",
        "print(cluster_members[['release_name', 'descriptors']])\n",
        "\n",
        "print(len(cluster_members[['release_name', 'descriptors']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFbhE8jMLE3-"
      },
      "outputs": [],
      "source": [
        "# model1 = None\n",
        "# model1 = model1(X_train, X_val, y_train, y_val, df, df_nparray, embed(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McPfMKHhmjqL",
        "outputId": "d48ba536-347b-4f96-9c04-fa691cd8f0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 6.4973 - accuracy: 0.0101\n",
            "Epoch 1: val_loss improved from inf to 4.65726, saving model to best_model.h5\n",
            "62/62 [==============================] - 10s 11ms/step - loss: 6.4215 - accuracy: 0.0104 - val_loss: 4.6573 - val_accuracy: 0.0121\n",
            "Epoch 2/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 4.6776 - accuracy: 0.0150\n",
            "Epoch 2: val_loss improved from 4.65726 to 4.58693, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 4.6661 - accuracy: 0.0144 - val_loss: 4.5869 - val_accuracy: 0.0182\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 4.5632 - accuracy: 0.0230\n",
            "Epoch 3: val_loss improved from 4.58693 to 4.37435, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 4.5632 - accuracy: 0.0230 - val_loss: 4.3744 - val_accuracy: 0.0354\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 4.1792 - accuracy: 0.0435\n",
            "Epoch 4: val_loss improved from 4.37435 to 3.80127, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 4.1792 - accuracy: 0.0435 - val_loss: 3.8013 - val_accuracy: 0.0709\n",
            "Epoch 5/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 3.6790 - accuracy: 0.0807\n",
            "Epoch 5: val_loss improved from 3.80127 to 3.19899, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.6596 - accuracy: 0.0818 - val_loss: 3.1990 - val_accuracy: 0.1285\n",
            "Epoch 6/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 3.2387 - accuracy: 0.1160\n",
            "Epoch 6: val_loss improved from 3.19899 to 2.82404, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2287 - accuracy: 0.1172 - val_loss: 2.8240 - val_accuracy: 0.1609\n",
            "Epoch 7/100\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 3.0348 - accuracy: 0.1467\n",
            "Epoch 7: val_loss improved from 2.82404 to 2.67076, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.0314 - accuracy: 0.1450 - val_loss: 2.6708 - val_accuracy: 0.2115\n",
            "Epoch 8/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 2.9151 - accuracy: 0.1519\n",
            "Epoch 8: val_loss improved from 2.67076 to 2.57546, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.9068 - accuracy: 0.1559 - val_loss: 2.5755 - val_accuracy: 0.2206\n",
            "Epoch 9/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 2.8051 - accuracy: 0.1772\n",
            "Epoch 9: val_loss improved from 2.57546 to 2.48417, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.8118 - accuracy: 0.1782 - val_loss: 2.4842 - val_accuracy: 0.2348\n",
            "Epoch 10/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 2.7126 - accuracy: 0.1923\n",
            "Epoch 10: val_loss improved from 2.48417 to 2.36454, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.7097 - accuracy: 0.1936 - val_loss: 2.3645 - val_accuracy: 0.2672\n",
            "Epoch 11/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 2.6043 - accuracy: 0.2236\n",
            "Epoch 11: val_loss improved from 2.36454 to 2.22783, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.6092 - accuracy: 0.2253 - val_loss: 2.2278 - val_accuracy: 0.3289\n",
            "Epoch 12/100\n",
            "60/62 [============================>.] - ETA: 0s - loss: 2.5025 - accuracy: 0.2396\n",
            "Epoch 12: val_loss improved from 2.22783 to 2.17006, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5006 - accuracy: 0.2417 - val_loss: 2.1701 - val_accuracy: 0.3229\n",
            "Epoch 13/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 2.4337 - accuracy: 0.2573\n",
            "Epoch 13: val_loss improved from 2.17006 to 2.08710, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.4306 - accuracy: 0.2566 - val_loss: 2.0871 - val_accuracy: 0.3502\n",
            "Epoch 14/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 2.3661 - accuracy: 0.2568\n",
            "Epoch 14: val_loss improved from 2.08710 to 1.99138, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3631 - accuracy: 0.2577 - val_loss: 1.9914 - val_accuracy: 0.3593\n",
            "Epoch 15/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 2.3426 - accuracy: 0.2725\n",
            "Epoch 15: val_loss improved from 1.99138 to 1.95739, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.3440 - accuracy: 0.2716 - val_loss: 1.9574 - val_accuracy: 0.3826\n",
            "Epoch 16/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 2.2861 - accuracy: 0.2740\n",
            "Epoch 16: val_loss improved from 1.95739 to 1.92610, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.2890 - accuracy: 0.2789 - val_loss: 1.9261 - val_accuracy: 0.4079\n",
            "Epoch 17/100\n",
            "61/62 [============================>.] - ETA: 0s - loss: 2.2358 - accuracy: 0.2997\n",
            "Epoch 17: val_loss improved from 1.92610 to 1.86896, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.2349 - accuracy: 0.2994 - val_loss: 1.8690 - val_accuracy: 0.4241\n",
            "Epoch 18/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 2.2002 - accuracy: 0.3096\n",
            "Epoch 18: val_loss improved from 1.86896 to 1.80497, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.1950 - accuracy: 0.3093 - val_loss: 1.8050 - val_accuracy: 0.4362\n",
            "Epoch 19/100\n",
            "61/62 [============================>.] - ETA: 0s - loss: 2.1309 - accuracy: 0.3251\n",
            "Epoch 19: val_loss improved from 1.80497 to 1.73803, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.1310 - accuracy: 0.3247 - val_loss: 1.7380 - val_accuracy: 0.4656\n",
            "Epoch 20/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 2.0896 - accuracy: 0.3483\n",
            "Epoch 20: val_loss improved from 1.73803 to 1.71254, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.0861 - accuracy: 0.3478 - val_loss: 1.7125 - val_accuracy: 0.4605\n",
            "Epoch 21/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 2.0560 - accuracy: 0.3445\n",
            "Epoch 21: val_loss improved from 1.71254 to 1.69422, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.0548 - accuracy: 0.3442 - val_loss: 1.6942 - val_accuracy: 0.4656\n",
            "Epoch 22/100\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 2.0432 - accuracy: 0.3388\n",
            "Epoch 22: val_loss improved from 1.69422 to 1.65612, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0464 - accuracy: 0.3392 - val_loss: 1.6561 - val_accuracy: 0.4727\n",
            "Epoch 23/100\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.9823 - accuracy: 0.3729\n",
            "Epoch 23: val_loss improved from 1.65612 to 1.60645, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.9850 - accuracy: 0.3731 - val_loss: 1.6065 - val_accuracy: 0.5061\n",
            "Epoch 24/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 1.9827 - accuracy: 0.3694\n",
            "Epoch 24: val_loss improved from 1.60645 to 1.58574, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.9885 - accuracy: 0.3667 - val_loss: 1.5857 - val_accuracy: 0.5162\n",
            "Epoch 25/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.9344 - accuracy: 0.3736\n",
            "Epoch 25: val_loss improved from 1.58574 to 1.52517, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.9213 - accuracy: 0.3751 - val_loss: 1.5252 - val_accuracy: 0.5253\n",
            "Epoch 26/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 1.9025 - accuracy: 0.3884\n",
            "Epoch 26: val_loss did not improve from 1.52517\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9078 - accuracy: 0.3890 - val_loss: 1.5276 - val_accuracy: 0.5071\n",
            "Epoch 27/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 1.8897 - accuracy: 0.3956\n",
            "Epoch 27: val_loss improved from 1.52517 to 1.50391, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.8932 - accuracy: 0.3984 - val_loss: 1.5039 - val_accuracy: 0.5243\n",
            "Epoch 28/100\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 1.8372 - accuracy: 0.4116\n",
            "Epoch 28: val_loss improved from 1.50391 to 1.47488, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.8397 - accuracy: 0.4105 - val_loss: 1.4749 - val_accuracy: 0.5273\n",
            "Epoch 29/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.8148 - accuracy: 0.4114\n",
            "Epoch 29: val_loss improved from 1.47488 to 1.45851, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.8213 - accuracy: 0.4047 - val_loss: 1.4585 - val_accuracy: 0.5536\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7990 - accuracy: 0.4224\n",
            "Epoch 30: val_loss improved from 1.45851 to 1.43405, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.7990 - accuracy: 0.4224 - val_loss: 1.4341 - val_accuracy: 0.5577\n",
            "Epoch 31/100\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 1.7841 - accuracy: 0.4243\n",
            "Epoch 31: val_loss improved from 1.43405 to 1.42357, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.7912 - accuracy: 0.4234 - val_loss: 1.4236 - val_accuracy: 0.5364\n",
            "Epoch 32/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 1.7532 - accuracy: 0.4318\n",
            "Epoch 32: val_loss improved from 1.42357 to 1.42129, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.7650 - accuracy: 0.4318 - val_loss: 1.4213 - val_accuracy: 0.5445\n",
            "Epoch 33/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 1.7290 - accuracy: 0.4366\n",
            "Epoch 33: val_loss improved from 1.42129 to 1.37712, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.7395 - accuracy: 0.4351 - val_loss: 1.3771 - val_accuracy: 0.5668\n",
            "Epoch 34/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.7202 - accuracy: 0.4361\n",
            "Epoch 34: val_loss did not improve from 1.37712\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7253 - accuracy: 0.4328 - val_loss: 1.3968 - val_accuracy: 0.5547\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7042 - accuracy: 0.4409\n",
            "Epoch 35: val_loss did not improve from 1.37712\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7042 - accuracy: 0.4409 - val_loss: 1.3820 - val_accuracy: 0.5567\n",
            "Epoch 36/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.6883 - accuracy: 0.4410\n",
            "Epoch 36: val_loss improved from 1.37712 to 1.32505, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.6901 - accuracy: 0.4419 - val_loss: 1.3251 - val_accuracy: 0.5830\n",
            "Epoch 37/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.6674 - accuracy: 0.4618\n",
            "Epoch 37: val_loss did not improve from 1.32505\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6679 - accuracy: 0.4619 - val_loss: 1.3252 - val_accuracy: 0.5698\n",
            "Epoch 38/100\n",
            "55/62 [=========================>....] - ETA: 0s - loss: 1.6849 - accuracy: 0.4548\n",
            "Epoch 38: val_loss did not improve from 1.32505\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6774 - accuracy: 0.4541 - val_loss: 1.3342 - val_accuracy: 0.5709\n",
            "Epoch 39/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.6378 - accuracy: 0.4545\n",
            "Epoch 39: val_loss improved from 1.32505 to 1.28803, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.6436 - accuracy: 0.4536 - val_loss: 1.2880 - val_accuracy: 0.5982\n",
            "Epoch 40/100\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6177 - accuracy: 0.4633\n",
            "Epoch 40: val_loss improved from 1.28803 to 1.28724, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.6183 - accuracy: 0.4637 - val_loss: 1.2872 - val_accuracy: 0.5911\n",
            "Epoch 41/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.5919 - accuracy: 0.4674\n",
            "Epoch 41: val_loss improved from 1.28724 to 1.27884, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.5990 - accuracy: 0.4665 - val_loss: 1.2788 - val_accuracy: 0.5951\n",
            "Epoch 42/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.6094 - accuracy: 0.4696\n",
            "Epoch 42: val_loss improved from 1.27884 to 1.26154, saving model to best_model.h5\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.6012 - accuracy: 0.4728 - val_loss: 1.2615 - val_accuracy: 0.5962\n",
            "Epoch 43/100\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 1.5895 - accuracy: 0.4720\n",
            "Epoch 43: val_loss did not improve from 1.26154\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.5952 - accuracy: 0.4695 - val_loss: 1.2788 - val_accuracy: 0.5830\n",
            "Epoch 44/100\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.5843 - accuracy: 0.4793\n",
            "Epoch 44: val_loss improved from 1.26154 to 1.25006, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.5833 - accuracy: 0.4799 - val_loss: 1.2501 - val_accuracy: 0.6022\n",
            "Epoch 45/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.5521 - accuracy: 0.4811\n",
            "Epoch 45: val_loss improved from 1.25006 to 1.23621, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5511 - accuracy: 0.4801 - val_loss: 1.2362 - val_accuracy: 0.6113\n",
            "Epoch 46/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.5755 - accuracy: 0.4783\n",
            "Epoch 46: val_loss did not improve from 1.23621\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5802 - accuracy: 0.4773 - val_loss: 1.2410 - val_accuracy: 0.5941\n",
            "Epoch 47/100\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.5359 - accuracy: 0.4859\n",
            "Epoch 47: val_loss improved from 1.23621 to 1.20592, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.5377 - accuracy: 0.4842 - val_loss: 1.2059 - val_accuracy: 0.6245\n",
            "Epoch 48/100\n",
            "57/62 [==========================>...] - ETA: 0s - loss: 1.4972 - accuracy: 0.4874\n",
            "Epoch 48: val_loss improved from 1.20592 to 1.19001, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.5033 - accuracy: 0.4849 - val_loss: 1.1900 - val_accuracy: 0.6174\n",
            "Epoch 49/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.5137 - accuracy: 0.4960\n",
            "Epoch 49: val_loss improved from 1.19001 to 1.18446, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.5064 - accuracy: 0.4978 - val_loss: 1.1845 - val_accuracy: 0.6235\n",
            "Epoch 50/100\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 1.4892 - accuracy: 0.5019\n",
            "Epoch 50: val_loss did not improve from 1.18446\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.4931 - accuracy: 0.4999 - val_loss: 1.2092 - val_accuracy: 0.5911\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.4744 - accuracy: 0.5118\n",
            "Epoch 51: val_loss improved from 1.18446 to 1.17864, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.4744 - accuracy: 0.5118 - val_loss: 1.1786 - val_accuracy: 0.6204\n",
            "Epoch 52/100\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 1.4687 - accuracy: 0.5237\n",
            "Epoch 52: val_loss improved from 1.17864 to 1.14532, saving model to best_model.h5\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.4651 - accuracy: 0.5247 - val_loss: 1.1453 - val_accuracy: 0.6366\n",
            "Epoch 53/100\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.4434 - accuracy: 0.5214\n",
            "Epoch 53: val_loss did not improve from 1.14532\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.4403 - accuracy: 0.5237 - val_loss: 1.1680 - val_accuracy: 0.6204\n",
            "Epoch 54/100\n",
            "54/62 [=========================>....] - ETA: 0s - loss: 1.4504 - accuracy: 0.5127\n",
            "Epoch 54: val_loss did not improve from 1.14532\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.4570 - accuracy: 0.5108 - val_loss: 1.1685 - val_accuracy: 0.6164\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.4533 - accuracy: 0.5128Restoring model weights from the end of the best epoch: 52.\n",
            "\n",
            "Epoch 55: val_loss did not improve from 1.14532\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.4533 - accuracy: 0.5128 - val_loss: 1.1491 - val_accuracy: 0.6366\n",
            "Epoch 55: early stopping\n"
          ]
        }
      ],
      "source": [
        "model2 = model2(X_train, X_val, y_train, y_val, df, df_nparray)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. get lyrics (implement them)\n",
        "2. maybe take out some of the descriptors in the train/test split (20% of the descriptors are not used in training, in order to test if users use words not in vocab what would happen)\n",
        "3. get some F1 scores\n",
        "4. get reviews (discog), then implement those\n",
        "5. 1 IMPLEMENT GENRES 1"
      ],
      "metadata": {
        "id": "Fg3bbcXJ9x3G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHGjqNMfTr96"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}